{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMFXfINpoaA1fftac2q/wkN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"gLOaGonj9umH","executionInfo":{"status":"ok","timestamp":1699548309206,"user_tz":-540,"elapsed":4,"user":{"displayName":"Флюгер Инвестора","userId":"12590526684121717153"}}},"outputs":[],"source":["from google.colab import files"]},{"cell_type":"code","source":["%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","%pip install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B6OzGEstBoeb","executionInfo":{"status":"ok","timestamp":1699549283217,"user_tz":-540,"elapsed":13494,"user":{"displayName":"Флюгер Инвестора","userId":"12590526684121717153"}},"outputId":"d7f6cc86-62e0-4f58-fe9f-fe1cb745d986"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://download.pytorch.org/whl/cu118\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Collecting ultralytics\n","  Downloading ultralytics-8.0.208-py3-none-any.whl (645 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.2/645.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.3)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu118)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu118)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Collecting thop>=0.1.1 (from ultralytics)\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.44.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Installing collected packages: thop, ultralytics\n","Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.208\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO, checks, hub\n","import os\n","import cv2\n","import csv"],"metadata":{"id":"hMwRZYRp_gZ6","executionInfo":{"status":"ok","timestamp":1699549300856,"user_tz":-540,"elapsed":8803,"user":{"displayName":"Флюгер Инвестора","userId":"12590526684121717153"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["file = files.upload()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"jh2AtQvt-SUB","executionInfo":{"status":"ok","timestamp":1699550122705,"user_tz":-540,"elapsed":375377,"user":{"displayName":"Флюгер Инвестора","userId":"12590526684121717153"}},"outputId":"688e320a-9fe2-4e62-cf43-2662bb4a9875"},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-6ba1c76c-7f18-415a-9fd3-e438cb099615\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-6ba1c76c-7f18-415a-9fd3-e438cb099615\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving 1.mp4 to 1 (2).mp4\n","None\n"]}]},{"cell_type":"code","source":["list(file.keys())[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"9rFdnBuxF2as","executionInfo":{"status":"ok","timestamp":1699550486263,"user_tz":-540,"elapsed":353,"user":{"displayName":"Флюгер Инвестора","userId":"12590526684121717153"}},"outputId":"c0fa0213-3e6e-46ac-af21-075e621b0074"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1 (2).mp4'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["def recognize(filename):\n","    #VIDEOS_DIR = os.path.join('.', 'videos')\n","    #video_path = os.path.join(VIDEOS_DIR, filename)\n","    video_path_out = '{}_out.mp4'.format(filename)\n","\n","    cap = cv2.VideoCapture(filename)\n","    ret, frame = cap.read()\n","    H, W, _ = frame.shape\n","    out = cv2.VideoWriter(video_path_out, cv2.VideoWriter_fourcc(*'mp4v'), int(cap.get(cv2.CAP_PROP_FPS)), (W, H))\n","\n","    model_path = 'weapon_yolo8.v1i.pt'\n","    # Load a model\n","    model = YOLO(model_path)  # load a custom model\n","\n","    threshold = 0.2\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    print(\"--- fps --- {}\".format(fps))\n","    cases = 0\n","    cur_frame = 0\n","    cur_hour = 0\n","    cur_min = 0\n","    cur_sec = 0\n","    cur_frame_buffer = 0\n","    timestamps = list()\n","    last_frame_detected = 0\n","\n","    while ret:\n","        # work with time\n","        cur_frame += 1\n","        cur_frame_buffer += 1\n","        if (cur_frame_buffer >= fps):\n","            cur_sec += 1\n","            cur_frame_buffer = 0\n","        else:\n","            out.write(frame)\n","            ret, frame = cap.read()\n","            continue\n","\n","        if (cur_sec > 59):\n","            cur_min += 1\n","            cur_sec = 0\n","        if (cur_min > 59):\n","            cur_min = 0\n","            cur_hour += 1\n","\n","        results = model(frame)[0]\n","\n","        for result in results.boxes.data.tolist():\n","            x1, y1, x2, y2, score, class_id = result\n","\n","            if (score > threshold):\n","                # Detected\n","                last_frame_detected = cur_frame\n","                cases += 1\n","                timestamps.append(\"{}:{}\".format(cur_min, cur_sec))\n","\n","                print(\"---------------------------------------------------------------------------------\")\n","                print(\"frame {} ==== time {}:{} ====\".format(cur_frame, cur_min, cur_sec))\n","                print(result)\n","                print(\"---------------------------------------------------------------------------------\")\n","                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)\n","                cv2.putText(frame, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),\n","                            cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n","\n","        out.write(frame)\n","        ret, frame = cap.read()\n","\n","    # decision format\n","    decision = list()\n","    decision.append(filename)\n","    decision.append(cases)\n","    decision.append(timestamps)\n","\n","    cap.release()\n","    out.release()\n","    cv2.destroyAllWindows()\n","\n","    return decision\n"],"metadata":{"id":"BK3LzOAG_i5G","executionInfo":{"status":"ok","timestamp":1699549307506,"user_tz":-540,"elapsed":331,"user":{"displayName":"Флюгер Инвестора","userId":"12590526684121717153"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def button_function():\n","    submission = \"result.csv\"\n","    with open(submission, mode=\"w\", encoding='utf-8') as w_file:\n","        file_writer = csv.writer(w_file, delimiter=\";\", lineterminator=\"\\r\")\n","        file_writer.writerow([\"filename\", \"cases_count\", \"timestamps\"])\n","        # f = os.path.join(directory, \"1.mp4\")\n","\n","        decision = recognize(list(file.keys())[0])  # uploaded file\n","        print(decision)\n","        file_writer.writerow(decision)"],"metadata":{"id":"azZg-Ft__o-T","executionInfo":{"status":"ok","timestamp":1699550512817,"user_tz":-540,"elapsed":3,"user":{"displayName":"Флюгер Инвестора","userId":"12590526684121717153"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["button_function()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aOP-0Sq2_uIF","executionInfo":{"status":"ok","timestamp":1699551569012,"user_tz":-540,"elapsed":1054210,"user":{"displayName":"Флюгер Инвестора","userId":"12590526684121717153"}},"outputId":"8cc40bd0-f394-4eb2-cfa8-b44eb5d3a594"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["--- fps --- 25.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 384x640 (no detections), 2879.9ms\n","Speed: 17.9ms preprocess, 2879.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2633.9ms\n","Speed: 3.7ms preprocess, 2633.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2947.1ms\n","Speed: 5.3ms preprocess, 2947.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3232.9ms\n","Speed: 7.0ms preprocess, 3232.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2633.3ms\n","Speed: 3.5ms preprocess, 2633.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2649.9ms\n","Speed: 3.9ms preprocess, 2649.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3431.5ms\n","Speed: 4.1ms preprocess, 3431.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2799.2ms\n","Speed: 3.9ms preprocess, 2799.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2630.6ms\n","Speed: 3.5ms preprocess, 2630.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2646.7ms\n","Speed: 3.9ms preprocess, 2646.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3882.6ms\n","Speed: 3.1ms preprocess, 3882.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2628.9ms\n","Speed: 3.6ms preprocess, 2628.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2642.4ms\n","Speed: 3.7ms preprocess, 2642.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2642.8ms\n","Speed: 4.0ms preprocess, 2642.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3904.8ms\n","Speed: 4.1ms preprocess, 3904.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2689.6ms\n","Speed: 3.8ms preprocess, 2689.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2634.5ms\n","Speed: 4.6ms preprocess, 2634.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3686.6ms\n","Speed: 3.8ms preprocess, 3686.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3050.8ms\n","Speed: 3.7ms preprocess, 3050.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2643.9ms\n","Speed: 5.0ms preprocess, 2643.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2640.1ms\n","Speed: 5.5ms preprocess, 2640.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3629.3ms\n","Speed: 4.7ms preprocess, 3629.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2622.0ms\n","Speed: 4.5ms preprocess, 2622.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2631.1ms\n","Speed: 3.6ms preprocess, 2631.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2616.1ms\n","Speed: 4.3ms preprocess, 2616.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3934.7ms\n","Speed: 3.7ms preprocess, 3934.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2635.7ms\n","Speed: 3.5ms preprocess, 2635.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2626.7ms\n","Speed: 3.8ms preprocess, 2626.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2627.0ms\n","Speed: 3.4ms preprocess, 2627.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3907.5ms\n","Speed: 3.8ms preprocess, 3907.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2634.7ms\n","Speed: 4.0ms preprocess, 2634.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2644.2ms\n","Speed: 5.0ms preprocess, 2644.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2722.9ms\n","Speed: 5.2ms preprocess, 2722.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3525.2ms\n","Speed: 5.2ms preprocess, 3525.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2674.9ms\n","Speed: 4.1ms preprocess, 2674.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2642.8ms\n","Speed: 3.5ms preprocess, 2642.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3234.1ms\n","Speed: 3.4ms preprocess, 3234.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3039.0ms\n","Speed: 4.0ms preprocess, 3039.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2633.6ms\n","Speed: 3.5ms preprocess, 2633.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2639.5ms\n","Speed: 3.6ms preprocess, 2639.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3621.6ms\n","Speed: 3.9ms preprocess, 3621.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2701.1ms\n","Speed: 3.8ms preprocess, 2701.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2644.2ms\n","Speed: 4.3ms preprocess, 2644.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2658.5ms\n","Speed: 3.7ms preprocess, 2658.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3951.4ms\n","Speed: 4.2ms preprocess, 3951.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2634.0ms\n","Speed: 3.9ms preprocess, 2634.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2632.9ms\n","Speed: 3.6ms preprocess, 2632.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2629.3ms\n","Speed: 4.3ms preprocess, 2629.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3909.1ms\n","Speed: 4.1ms preprocess, 3909.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2654.4ms\n","Speed: 4.0ms preprocess, 2654.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2656.7ms\n","Speed: 5.0ms preprocess, 2656.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2724.6ms\n","Speed: 3.7ms preprocess, 2724.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3498.1ms\n","Speed: 3.5ms preprocess, 3498.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2649.6ms\n","Speed: 3.9ms preprocess, 2649.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2696.8ms\n","Speed: 3.5ms preprocess, 2696.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3239.3ms\n","Speed: 4.7ms preprocess, 3239.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3035.1ms\n","Speed: 3.7ms preprocess, 3035.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2634.6ms\n","Speed: 3.9ms preprocess, 2634.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2634.8ms\n","Speed: 3.6ms preprocess, 2634.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3683.8ms\n","Speed: 4.2ms preprocess, 3683.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2634.3ms\n","Speed: 6.0ms preprocess, 2634.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2640.2ms\n","Speed: 3.6ms preprocess, 2640.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2650.4ms\n","Speed: 3.8ms preprocess, 2650.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3944.2ms\n","Speed: 4.7ms preprocess, 3944.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2651.8ms\n","Speed: 3.5ms preprocess, 2651.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2632.6ms\n","Speed: 4.6ms preprocess, 2632.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2626.5ms\n","Speed: 5.8ms preprocess, 2626.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3795.0ms\n","Speed: 7.6ms preprocess, 3795.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2619.4ms\n","Speed: 5.0ms preprocess, 2619.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2659.4ms\n","Speed: 3.5ms preprocess, 2659.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2896.2ms\n","Speed: 7.4ms preprocess, 2896.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3329.5ms\n","Speed: 12.5ms preprocess, 3329.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2698.5ms\n","Speed: 3.2ms preprocess, 2698.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2633.4ms\n","Speed: 3.9ms preprocess, 2633.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3356.0ms\n","Speed: 3.6ms preprocess, 3356.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2856.6ms\n","Speed: 3.7ms preprocess, 2856.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2627.1ms\n","Speed: 4.3ms preprocess, 2627.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2649.0ms\n","Speed: 3.9ms preprocess, 2649.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3778.8ms\n","Speed: 7.5ms preprocess, 3778.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2637.5ms\n","Speed: 3.9ms preprocess, 2637.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2653.2ms\n","Speed: 2.7ms preprocess, 2653.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2652.2ms\n","Speed: 3.7ms preprocess, 2652.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3915.5ms\n","Speed: 2.9ms preprocess, 3915.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2667.4ms\n","Speed: 3.6ms preprocess, 2667.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2677.4ms\n","Speed: 5.2ms preprocess, 2677.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2717.8ms\n","Speed: 4.6ms preprocess, 2717.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3537.0ms\n","Speed: 3.8ms preprocess, 3537.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2630.4ms\n","Speed: 4.4ms preprocess, 2630.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2612.0ms\n","Speed: 4.0ms preprocess, 2612.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3139.4ms\n","Speed: 5.5ms preprocess, 3139.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3171.5ms\n","Speed: 6.3ms preprocess, 3171.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2647.8ms\n","Speed: 4.6ms preprocess, 2647.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2670.4ms\n","Speed: 3.6ms preprocess, 2670.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3656.4ms\n","Speed: 4.0ms preprocess, 3656.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2639.4ms\n","Speed: 4.3ms preprocess, 2639.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2649.0ms\n","Speed: 6.4ms preprocess, 2649.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2649.0ms\n","Speed: 3.6ms preprocess, 2649.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3930.5ms\n","Speed: 4.3ms preprocess, 3930.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2655.9ms\n","Speed: 5.5ms preprocess, 2655.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2673.9ms\n","Speed: 3.7ms preprocess, 2673.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2680.9ms\n","Speed: 3.6ms preprocess, 2680.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3700.7ms\n","Speed: 6.6ms preprocess, 3700.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2660.8ms\n","Speed: 3.9ms preprocess, 2660.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2661.9ms\n","Speed: 3.6ms preprocess, 2661.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3071.3ms\n","Speed: 4.8ms preprocess, 3071.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3127.0ms\n","Speed: 4.1ms preprocess, 3127.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2644.3ms\n","Speed: 5.1ms preprocess, 2644.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2675.8ms\n","Speed: 3.8ms preprocess, 2675.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3752.7ms\n","Speed: 3.6ms preprocess, 3752.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2653.7ms\n","Speed: 4.5ms preprocess, 2653.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2652.3ms\n","Speed: 5.5ms preprocess, 2652.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2668.2ms\n","Speed: 6.0ms preprocess, 2668.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3948.4ms\n","Speed: 4.7ms preprocess, 3948.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2661.5ms\n","Speed: 4.0ms preprocess, 2661.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2867.9ms\n","Speed: 3.6ms preprocess, 2867.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2756.3ms\n","Speed: 3.7ms preprocess, 2756.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3489.0ms\n","Speed: 5.1ms preprocess, 3489.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2652.7ms\n","Speed: 4.0ms preprocess, 2652.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2679.0ms\n","Speed: 4.6ms preprocess, 2679.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3273.3ms\n","Speed: 3.8ms preprocess, 3273.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3168.2ms\n","Speed: 3.9ms preprocess, 3168.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3266.5ms\n","Speed: 5.9ms preprocess, 3266.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3560.3ms\n","Speed: 3.8ms preprocess, 3560.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3506.8ms\n","Speed: 6.1ms preprocess, 3506.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2667.4ms\n","Speed: 5.3ms preprocess, 2667.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2708.5ms\n","Speed: 6.3ms preprocess, 2708.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3295.7ms\n","Speed: 3.6ms preprocess, 3295.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2979.1ms\n","Speed: 6.0ms preprocess, 2979.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2667.3ms\n","Speed: 2.9ms preprocess, 2667.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2671.3ms\n","Speed: 3.6ms preprocess, 2671.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3824.8ms\n","Speed: 3.7ms preprocess, 3824.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2670.4ms\n","Speed: 4.0ms preprocess, 2670.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2665.4ms\n","Speed: 4.6ms preprocess, 2665.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2679.0ms\n","Speed: 4.0ms preprocess, 2679.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3966.9ms\n","Speed: 3.7ms preprocess, 3966.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2695.1ms\n","Speed: 4.3ms preprocess, 2695.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2665.4ms\n","Speed: 3.3ms preprocess, 2665.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2762.4ms\n","Speed: 3.6ms preprocess, 2762.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3501.6ms\n","Speed: 3.8ms preprocess, 3501.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2658.6ms\n","Speed: 3.8ms preprocess, 2658.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2635.8ms\n","Speed: 4.9ms preprocess, 2635.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3262.0ms\n","Speed: 3.8ms preprocess, 3262.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2934.9ms\n","Speed: 3.5ms preprocess, 2934.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2733.6ms\n","Speed: 6.0ms preprocess, 2733.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2654.2ms\n","Speed: 4.1ms preprocess, 2654.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3882.4ms\n","Speed: 4.6ms preprocess, 3882.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2648.9ms\n","Speed: 4.7ms preprocess, 2648.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2635.2ms\n","Speed: 3.9ms preprocess, 2635.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2663.6ms\n","Speed: 3.6ms preprocess, 2663.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3928.3ms\n","Speed: 3.9ms preprocess, 3928.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2642.7ms\n","Speed: 3.9ms preprocess, 2642.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2664.8ms\n","Speed: 4.2ms preprocess, 2664.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2729.4ms\n","Speed: 5.6ms preprocess, 2729.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3494.9ms\n","Speed: 11.7ms preprocess, 3494.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2670.5ms\n","Speed: 4.2ms preprocess, 2670.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2663.2ms\n","Speed: 3.6ms preprocess, 2663.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3236.6ms\n","Speed: 3.9ms preprocess, 3236.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3054.5ms\n","Speed: 3.7ms preprocess, 3054.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2659.4ms\n","Speed: 4.6ms preprocess, 2659.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2656.8ms\n","Speed: 3.7ms preprocess, 2656.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3714.6ms\n","Speed: 5.1ms preprocess, 3714.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2705.4ms\n","Speed: 5.5ms preprocess, 2705.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2650.4ms\n","Speed: 3.7ms preprocess, 2650.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2670.6ms\n","Speed: 4.4ms preprocess, 2670.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3942.3ms\n","Speed: 3.7ms preprocess, 3942.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2636.2ms\n","Speed: 4.1ms preprocess, 2636.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2652.0ms\n","Speed: 5.4ms preprocess, 2652.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2674.5ms\n","Speed: 5.2ms preprocess, 2674.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3757.0ms\n","Speed: 5.1ms preprocess, 3757.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2673.3ms\n","Speed: 4.5ms preprocess, 2673.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2675.7ms\n","Speed: 3.7ms preprocess, 2675.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3070.1ms\n","Speed: 4.9ms preprocess, 3070.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3154.3ms\n","Speed: 5.5ms preprocess, 3154.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2662.8ms\n","Speed: 4.4ms preprocess, 2662.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2634.9ms\n","Speed: 4.8ms preprocess, 2634.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3585.8ms\n","Speed: 3.8ms preprocess, 3585.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2662.5ms\n","Speed: 3.6ms preprocess, 2662.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2643.7ms\n","Speed: 3.6ms preprocess, 2643.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2675.5ms\n","Speed: 3.0ms preprocess, 2675.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 4011.9ms\n","Speed: 6.1ms preprocess, 4011.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2669.1ms\n","Speed: 5.4ms preprocess, 2669.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2649.5ms\n","Speed: 3.7ms preprocess, 2649.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2634.2ms\n","Speed: 3.7ms preprocess, 2634.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3881.3ms\n","Speed: 5.7ms preprocess, 3881.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2650.9ms\n","Speed: 3.8ms preprocess, 2650.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2663.4ms\n","Speed: 3.9ms preprocess, 2663.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2855.5ms\n","Speed: 4.4ms preprocess, 2855.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3400.8ms\n","Speed: 4.5ms preprocess, 3400.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2645.7ms\n","Speed: 5.2ms preprocess, 2645.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2658.7ms\n","Speed: 5.8ms preprocess, 2658.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3346.6ms\n","Speed: 5.0ms preprocess, 3346.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2989.6ms\n","Speed: 3.8ms preprocess, 2989.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2642.0ms\n","Speed: 4.4ms preprocess, 2642.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2657.2ms\n","Speed: 4.8ms preprocess, 2657.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3790.8ms\n","Speed: 5.6ms preprocess, 3790.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2658.6ms\n","Speed: 4.2ms preprocess, 2658.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2657.7ms\n","Speed: 5.8ms preprocess, 2657.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2697.9ms\n","Speed: 4.5ms preprocess, 2697.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3917.8ms\n","Speed: 4.2ms preprocess, 3917.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2669.6ms\n","Speed: 4.8ms preprocess, 2669.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2665.8ms\n","Speed: 4.1ms preprocess, 2665.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2664.9ms\n","Speed: 5.2ms preprocess, 2664.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3606.1ms\n","Speed: 6.8ms preprocess, 3606.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2667.4ms\n","Speed: 3.9ms preprocess, 2667.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2673.4ms\n","Speed: 4.2ms preprocess, 2673.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3154.2ms\n","Speed: 3.7ms preprocess, 3154.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3138.2ms\n","Speed: 3.8ms preprocess, 3138.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2659.4ms\n","Speed: 4.7ms preprocess, 2659.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2633.4ms\n","Speed: 3.6ms preprocess, 2633.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3635.1ms\n","Speed: 4.3ms preprocess, 3635.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2657.2ms\n","Speed: 3.8ms preprocess, 2657.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2661.6ms\n","Speed: 3.9ms preprocess, 2661.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2636.4ms\n","Speed: 4.4ms preprocess, 2636.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3943.1ms\n","Speed: 3.7ms preprocess, 3943.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2646.6ms\n","Speed: 4.3ms preprocess, 2646.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2721.1ms\n","Speed: 4.4ms preprocess, 2721.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2650.4ms\n","Speed: 3.7ms preprocess, 2650.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3790.7ms\n","Speed: 3.8ms preprocess, 3790.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2649.7ms\n","Speed: 3.7ms preprocess, 2649.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2656.1ms\n","Speed: 5.0ms preprocess, 2656.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2889.3ms\n","Speed: 4.2ms preprocess, 2889.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3343.3ms\n","Speed: 7.5ms preprocess, 3343.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2639.0ms\n","Speed: 5.7ms preprocess, 2639.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2670.3ms\n","Speed: 5.7ms preprocess, 2670.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3389.0ms\n","Speed: 4.6ms preprocess, 3389.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2870.0ms\n","Speed: 3.9ms preprocess, 2870.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2657.6ms\n","Speed: 3.6ms preprocess, 2657.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Pistol, 2671.8ms\n","Speed: 3.8ms preprocess, 2671.8ms inference, 22.9ms postprocess per image at shape (1, 3, 384, 640)\n"]},{"output_type":"stream","name":"stdout","text":["---------------------------------------------------------------------------------\n","frame 5700 ==== time 3:48 ====\n","[1191.1226806640625, 729.6823120117188, 1232.162841796875, 806.8292236328125, 0.653812825679779, 3.0]\n","---------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 384x640 (no detections), 3957.8ms\n","Speed: 4.2ms preprocess, 3957.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2650.6ms\n","Speed: 3.6ms preprocess, 2650.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2671.3ms\n","Speed: 4.3ms preprocess, 2671.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2652.2ms\n","Speed: 6.2ms preprocess, 2652.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3906.6ms\n","Speed: 4.2ms preprocess, 3906.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2693.7ms\n","Speed: 3.8ms preprocess, 2693.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2633.7ms\n","Speed: 3.0ms preprocess, 2633.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2831.9ms\n","Speed: 3.8ms preprocess, 2831.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3410.1ms\n","Speed: 3.7ms preprocess, 3410.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2669.7ms\n","Speed: 9.1ms preprocess, 2669.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2671.3ms\n","Speed: 5.6ms preprocess, 2671.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3381.8ms\n","Speed: 3.8ms preprocess, 3381.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2884.7ms\n","Speed: 3.5ms preprocess, 2884.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2658.7ms\n","Speed: 4.5ms preprocess, 2658.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2650.4ms\n","Speed: 5.8ms preprocess, 2650.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3831.3ms\n","Speed: 3.8ms preprocess, 3831.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2668.4ms\n","Speed: 4.7ms preprocess, 2668.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2648.3ms\n","Speed: 3.7ms preprocess, 2648.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2627.8ms\n","Speed: 4.7ms preprocess, 2627.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3946.4ms\n","Speed: 3.9ms preprocess, 3946.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2623.9ms\n","Speed: 5.2ms preprocess, 2623.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2631.4ms\n","Speed: 4.3ms preprocess, 2631.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2619.2ms\n","Speed: 2.8ms preprocess, 2619.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3779.8ms\n","Speed: 3.8ms preprocess, 3779.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2644.8ms\n","Speed: 3.8ms preprocess, 2644.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2647.2ms\n","Speed: 3.6ms preprocess, 2647.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3011.6ms\n","Speed: 4.5ms preprocess, 3011.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3215.5ms\n","Speed: 7.2ms preprocess, 3215.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2660.1ms\n","Speed: 3.6ms preprocess, 2660.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2648.7ms\n","Speed: 4.0ms preprocess, 2648.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 Pistol, 3530.6ms\n","Speed: 5.1ms preprocess, 3530.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"]},{"output_type":"stream","name":"stdout","text":["---------------------------------------------------------------------------------\n","frame 6475 ==== time 4:19 ====\n","[1100.0635986328125, 759.3310546875, 1170.833251953125, 840.2926025390625, 0.7330393195152283, 3.0]\n","---------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["\n","0: 384x640 (no detections), 2729.8ms\n","Speed: 6.8ms preprocess, 2729.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2636.5ms\n","Speed: 4.4ms preprocess, 2636.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2639.9ms\n","Speed: 3.6ms preprocess, 2639.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3935.0ms\n","Speed: 3.7ms preprocess, 3935.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2653.4ms\n","Speed: 4.1ms preprocess, 2653.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2636.9ms\n","Speed: 4.9ms preprocess, 2636.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2664.2ms\n","Speed: 3.9ms preprocess, 2664.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3907.4ms\n","Speed: 4.8ms preprocess, 3907.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2636.4ms\n","Speed: 3.8ms preprocess, 2636.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2642.4ms\n","Speed: 3.6ms preprocess, 2642.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2748.0ms\n","Speed: 4.6ms preprocess, 2748.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3500.8ms\n","Speed: 3.8ms preprocess, 3500.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2621.0ms\n","Speed: 3.7ms preprocess, 2621.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2625.7ms\n","Speed: 4.1ms preprocess, 2625.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3129.7ms\n","Speed: 3.9ms preprocess, 3129.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3146.4ms\n","Speed: 3.8ms preprocess, 3146.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2648.6ms\n","Speed: 3.9ms preprocess, 2648.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2646.5ms\n","Speed: 5.5ms preprocess, 2646.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3498.2ms\n","Speed: 3.8ms preprocess, 3498.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2741.9ms\n","Speed: 3.6ms preprocess, 2741.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2633.8ms\n","Speed: 3.8ms preprocess, 2633.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2655.7ms\n","Speed: 3.8ms preprocess, 2655.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3906.7ms\n","Speed: 3.8ms preprocess, 3906.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2646.3ms\n","Speed: 5.4ms preprocess, 2646.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2638.6ms\n","Speed: 3.8ms preprocess, 2638.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2631.5ms\n","Speed: 2.9ms preprocess, 2631.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3885.8ms\n","Speed: 3.6ms preprocess, 3885.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2641.1ms\n","Speed: 3.9ms preprocess, 2641.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2708.0ms\n","Speed: 7.2ms preprocess, 2708.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2666.4ms\n","Speed: 4.9ms preprocess, 2666.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3563.1ms\n","Speed: 3.5ms preprocess, 3563.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2659.4ms\n","Speed: 4.4ms preprocess, 2659.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2651.8ms\n","Speed: 6.1ms preprocess, 2651.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3127.1ms\n","Speed: 4.7ms preprocess, 3127.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3067.2ms\n","Speed: 7.4ms preprocess, 3067.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2644.3ms\n","Speed: 4.6ms preprocess, 2644.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2653.5ms\n","Speed: 3.9ms preprocess, 2653.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3587.5ms\n","Speed: 4.3ms preprocess, 3587.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2699.0ms\n","Speed: 5.6ms preprocess, 2699.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2643.5ms\n","Speed: 5.8ms preprocess, 2643.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 2643.6ms\n","Speed: 3.8ms preprocess, 2643.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 3951.8ms\n","Speed: 3.8ms preprocess, 3951.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"]},{"output_type":"stream","name":"stdout","text":["['1 (2).mp4', 2, ['3:48', '4:19']]\n"]}]}]}